# Dataset reader arguments
dataset:
  image_features_train_h5: 'data/train.h5'
  image_features_val_h5: 'data/val.h5'
  image_features_test_h5: 'data/test.h5'

  word_counts_json: 'data/visdial_1.0_word_counts_train.json'
  ext_word_counts_json: '/home/jkalogero/KBGN-Implementation/data/ext_vocab.json'
  # ext_word_counts_json: '/home/jkalogero/KBGN-Implementation/data/debug_ext_vocab.json'

  elmopath: 'data/elmo_1024.json'
  glovepath: 'data/glove.6B.300d.txt'
  numberbatchpath: 'data/transe/numberbatch-en-19.08.txt'

  transe: 'data/transe/glove.transe.sgd.ent.npy'
  numberbatch: 'data/transe/concept.nb.npy'

  elmo_visdial_path: 'data/elmo_visdial.json.npy'
  glove_visdial_path: 'data/glove_visdial.json.npy'
  numberbatch_visdial_path: 'data/numberbatch_visdial.json.npy'
  # numberbatch_visdial_path: 'data/debug_numberbatch_visdial.json.npy'

  
  tokenized_questions_train: 'data/tokenized_questions_train.json'
  tokenized_answers_train: 'data/tokenized_answers_train.json'
  tokenized_captions_train: 'data/tokenized_captions_train.json'
  tokenized_dialogs_train: 'data/tokenized_dialogs_train.json'
  tokenized_questions_val2018: 'data/tokenized_questions_val.json'
  tokenized_answers_val2018: 'data/tokenized_answers_val.json'
  tokenized_captions_val2018: 'data/tokenized_captions_val.json'
  tokenized_dialogs_val2018: 'data/tokenized_dialogs_val.json'
  tokenized_questions_test2018: 'data/tokenized_questions_test.json'
  tokenized_answers_test2018: 'data/tokenized_answers_test.json'
  tokenized_captions_test2018: 'data/tokenized_captions_test.json'
  tokenized_dialogs_test2018: 'data/tokenized_dialogs_test.json'

  conceptnet_vocab_file: 'data/cpnet/pad_concept.txt'

  img_norm: 1
  concat_history: false
  max_sequence_length: 20
  vocab_min_count: 5

  caption_round_num: 6
  caption_maxlen_each: 14

  multiple_relations: false
  num_relations: 17
  max_edges: 45
  max_nodes: 45


# Model related arguments
model:
  encoder: 'kbgn'
  decoder: 'disc'

  img_feature_size: 2048
  word_embedding_size: 300
  lstm_hidden_size: 512
  lstm_num_layers: 2
  dropout: 0.5
  # ext_dropout: 0.5
  numberbatch_dim: 300
  transe_dim: 100

  glove_embedding_size: 300
  elmo_embedding_size: 1024
  numberbatch_embedding_size: 300

  caption_word_size_out1: 256
  caption_lstm_numlayers_1: 2
  captionsize_todecoder: 512


  relation_dims: 512
  relation_change_num: 128


  ques_change_num: 256
  caption_change_num: 256

  num_relations: 17
  multiple_relations: false
  max_edges: 45
  max_nodes: 45

  # external knowledge gnn related arguments
  gnn: 'gcn'
  slope: 0.2 # as in paper
  n_heads: 8 # used only in gat
  gnn_dropout: 0.1

# Optimization related arguments
solver:
  batch_size: 4
  num_epochs: 10 # was 16
  initial_lr: 1e-3
  training_splits: "train"  # "trainval"
  lr_gamma: 0.1
  lr_milestones:
    - 5
    - 7
    - 10
  warmup_factor: 0.2
  warmup_epochs: 2
  eta_min: 0.00034
